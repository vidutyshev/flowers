{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vidutyshev/flowers/blob/main/Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Если что-то с зависимостями\n",
        "!pip install --upgrade torch torchvision sympy"
      ],
      "metadata": {
        "id": "DKoJ6e8JFCUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ссылка на архив на Google Диск с датасетом с https://www.kaggle.com/datasets/alxmamaev/flowers-recognition\n",
        "archive_url = 'https://drive.google.com/file/d/1PtGU9NM6hEHn2kEA7J4yVqI-1ci0iI2K/view?usp=sharing'\n",
        "!mkdir dataset_flw\n",
        "!gdown -O flowers.zip 1PtGU9NM6hEHn2kEA7J4yVqI-1ci0iI2K\n",
        "!unzip flowers.zip -d ./dataset_flw"
      ],
      "metadata": {
        "id": "eCLY5njVE1co"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEFQqlO8prEA",
        "outputId": "151851e3-c312-4ce0-d683-3057659e31be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Используется архитектура: cpu\n",
            "Всего классов: 0\n",
            "Класс \"daisy\" содержит 764 изображений\n",
            "Класс \"dandelion\" содержит 1052 изображений\n",
            "Класс \"rose\" содержит 784 изображений\n",
            "Класс \"sunflower\" содержит 733 изображений\n",
            "Класс \"tulip\" содержит 984 изображений\n",
            "\n",
            "Количество изображений: 4317\n",
            "Обучающая выборка: 3885\n",
            "Тестовая выборка: 432\n",
            "dimension_after_pooling: 57\n",
            "Эпоха 1 из 5\n",
            "Потери на обучающей выборке: 1.2085216596990747\n",
            "Метрика успешности (Acc) модели: 49.73%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn, optim\n",
        "import numpy as np\n",
        "\n",
        "# Путь до директории с изображениями\n",
        "data_dir = './dataset_flw/flowers/'\n",
        "\n",
        "# Запускаем на GPU, если есть\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Используется архитектура: {device}')\n",
        "\n",
        "# Обработка картинок\n",
        "dimension = 224 # Размер картинки до которого ресайзим все\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((dimension, dimension)),  # Все картинки одного размера\n",
        "    transforms.ToTensor(),         # Преобразуем картинку в тензор\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Нормализацяи изображерния\n",
        "])\n",
        "\n",
        "# Загружаем датасет из файлов в паках по классам\n",
        "dataset = datasets.ImageFolder(data_dir, transform=transform)\n",
        "\n",
        "# Получаем классы по названию папок\n",
        "classes = dataset.classes\n",
        "\n",
        "# Выводим инфо по количеству классов и картинок в них\n",
        "class_counts = {}\n",
        "print(\"Всего классов:\", len(class_counts))\n",
        "for img_path, label in dataset.imgs:\n",
        "    class_name = classes[label]\n",
        "    if class_name not in class_counts:\n",
        "        class_counts[class_name] = 0\n",
        "    class_counts[class_name] += 1\n",
        "for class_name, count in class_counts.items():\n",
        "    print(f'Класс \"{class_name}\" содержит {count} изображений')\n",
        "\n",
        "# Разделяем данные на обучающую и тестовую выборки\n",
        "train_test_ratio = 0.9\n",
        "train_size = int(train_test_ratio * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "\n",
        "# Выводим количество изображений в обучающей и тестовой выборках\n",
        "print(f'\\nКоличество изображений: {len(dataset)}')\n",
        "print(f'Обучающая выборка: {len(train_dataset)}')\n",
        "print(f'Тестовая выборка: {len(test_dataset)}')\n",
        "\n",
        "# Создаем загрузчики данных\n",
        "batch_size = 10 # Количество картинок в батче\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "# Определем параметры для пулинг слоя\n",
        "pooling_kernel_size = 4\n",
        "pooling_stride = 2\n",
        "pooling_padding = 2\n",
        "pooling_count = 2\n",
        "\n",
        "# Посчитаем размерность картинки после пулинг слоев\n",
        "dimension_after_pooling = dimension\n",
        "for i in range(pooling_count):\n",
        "  dimension_after_pooling = int((dimension_after_pooling - pooling_kernel_size + 2 * pooling_padding) / pooling_stride + 1)\n",
        "print (f'dimension_after_pooling: {dimension_after_pooling}')\n",
        "\n",
        "# Определяем архитектуру сети\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        # Первый сверточный слой с выходными 16 каналами\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
        "        # Добавляем батч-нормализацию к первому сверточному\n",
        "        self.bn1 = nn.BatchNorm2d(num_features=16)\n",
        "        # Пуллинг для уменьшения разрешения картинок\n",
        "        self.pool = nn.MaxPool2d(kernel_size=4, stride=2, padding=2)\n",
        "        # Второй  сверточный слой на 32 выходных канала\n",
        "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
        "        # Вторая батч-нормализация для второго сверточного слоя\n",
        "        self.bn2 = nn.BatchNorm2d(num_features=32)\n",
        "        # Первый линейный слой для преобразования в одномерный тензор на 64 нейрона\n",
        "        self.fc1 = nn.Linear(32 * dimension_after_pooling * dimension_after_pooling, 64)\n",
        "        # Батч-нормализация для одномерного тензора\n",
        "        self.bn3 = nn.BatchNorm1d(num_features=64)\n",
        "        # Второй линейный слой для раскладывания картинок по количеству классов\n",
        "        self.fc2 = nn.Linear(64, len(classes))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.bn1(self.conv1(x))))  # свертка - нормализация - функция возбуждения - пулинг\n",
        "        x = self.pool(torch.relu(self.bn2(self.conv2(x))))  # свертка - нормализация - функция возбуждения - пулинг\n",
        "        x = x.view(-1, 32 * dimension_after_pooling * dimension_after_pooling) # Преобразуем в одномерный тензор правильной размерности\n",
        "        x = torch.relu(self.bn3(self.fc1(x)))               # линейный слой - нормализация - функция возбуждения\n",
        "        x = self.fc2(x)                                     # второй линейный слой, выходной по классам\n",
        "        return x\n",
        "\n",
        "# Инициализируем модель в выбранной архитектуре\n",
        "model = CNN().to(device)\n",
        "\n",
        "# Инициализируем функцию потерь и оптимизатор Adam\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "# Обучаем модель за 5 циклов(эпох)\n",
        "count_epoch = 5\n",
        "for epoch in range(count_epoch):\n",
        "    loss_batch = 0.0   # Потери по батчу\n",
        "    correct = 0        # Кол-во правильно предсказанных\n",
        "    total = 0          # Всего картинок\n",
        "\n",
        "    for i, data in enumerate(train_loader, 0): # Идем по батчам в обучающей выборке\n",
        "        # Распаковываем входные данные на отедльно картинки и классы\n",
        "        inputs, labels = data\n",
        "        # Загружаем данные в выбранную архитектуру\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()  # Сбрасываем градиенты\n",
        "\n",
        "        outputs = model(inputs) # Прогоняем входные данные через модель\n",
        "        loss = loss_func(outputs, labels) # Считаем потери\n",
        "        # Вычисляем градиент функции потерь с обратным распространением\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Получаем предсказанный класс с максимальной вероятностью отнесения\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0) # Считаем сколько всего в батче файлов\n",
        "        # Вычисляем кол-во корректно предсказанных картинок\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        # Суммируем значение потерь по батчам\n",
        "        loss_batch += loss.item()\n",
        "    # Выводим\n",
        "    print(f'Эпоха {epoch + 1} из {count_epoch}')\n",
        "    print(f'Потери на обучающей выборке: {loss_batch / len(train_loader)}')\n",
        "    print(f'Метрика успешности (Acc) модели: {(100 * correct / total):.2f}%\\n')\n",
        "\n",
        "# Проверяем модель на тестовой выборке\n",
        "with torch.no_grad(): # Модель не обучаем, поэтому считаем без обратного распростронения\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    # Разбираем тестовый датасет на батчи\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        # Загружаем данные  в выбранную архитектуру\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images) # Прогоняем мданные через модель\n",
        "        # Получаем предсказанный класс с максимальной вероятностью отнесения\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        # Считаем количество всех меток и количество корректно определенных\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Метрика успешности (Acc) модели на тестововй выборке: %.2f %%' % (100 * correct / total))\n",
        "# Записваем модель в файл\n",
        "torch.save(model.state_dict(), 'trained_model.pt')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO2x3pgrZuPM3KlnMO2LXmr",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}